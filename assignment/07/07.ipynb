{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file = 'sqlResult_1558435.csv'\n",
    "\n",
    "content = pd.read_csv(file, encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/体验版内测，稳定版暂不受影响），以确保工程师可以集中全部精力进行系统优化工作。有人猜测这也是将精力主要用到MIUI 9的研发之中。\\r\\nMIUI 8去年5月发布，距今已有一年有余，也是时候更新换代了。\\r\\n当然，关于MIUI 9的确切信息，我们还是等待官方消息。\\r\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content['content'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content['xinhua'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(content)):\n",
    "    if content.iloc[i, 2] == '新华社':\n",
    "        content.loc[i, 'xinhua'] = 1\n",
    "    else:\n",
    "        content.loc[i, 'xinhua'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = content[['content']], content[['xinhua']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>（原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  此外，自本周（6月12日）起，除小米手机6等15款机型外，其余机型已暂停更新发布（含开发版/...\n",
       "1  骁龙835作为唯一通过Windows 10桌面平台认证的ARM处理器，高通强调，不会因为只考...\n",
       "2  此前的一加3T搭载的是3400mAh电池，DashCharge快充规格为5V/4A。\\r\\n...\n",
       "3    这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车。新华社记者张立云摄\\r\\n\n",
       "4  （原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\r\\n@深圳交警微博称：昨日清..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/yl/ccsmswvj1vv4vglqr86wgbpw0000gn/T/jieba.cache\n",
      "Loading model cost 1.031 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "new_X = []\n",
    "for i in range(len(X)):\n",
    "    tmp = re.sub('[\\\\a-zA-Z0-9，。（）/：…@！？\\s\\n]', '', str(X.iloc[i, 0]))\n",
    "    new_X.append(' '.join(jieba.cut(tmp)))\n",
    "new_X = pd.Series(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外 自 本周 月 日 起 除 小米 手机 等款 机型 外 其余 机型 已 暂停 更新 发布 含 开发 版 体验版 内测 稳定版 暂不受 影响 以 确保 工程师 可以 集中 全部 精力 进行 系统优化 工作 有人 猜测 这 也 是 将 精力 主要 用到 的 研发 之中 去年 月 发布 距今已有 一年 有余 也 是 时候 更新换代 了 当然 关于 的 确切 信息 我们 还是 等待 官方消息'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfVectorizer()\n",
    "X_tfidf = transformer.fit_transform(new_X)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_validation, X_test, y_train_validation, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=1988)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train_validation, y_train_validation, test_size=0.25, random_state=1988)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenjiazhai/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/wenjiazhai/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()\n",
    "model_lg = lg.fit(X_train, y_train)\n",
    "pred_lg = lg.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1749,   489],\n",
       "       [   91, 15593]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_validation, pred_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 96.76375404530745%; precision: 78.15013404825737%;\n",
      "recall: 95.05434782608695%.f1 score: 85.77734183423247\n"
     ]
    }
   ],
   "source": [
    "acc_lr = (1749+15593) / (1749+489+91+15593) * 100\n",
    "precision_lr = 1749 / (1749+489) * 100\n",
    "recall_lr = 1749 / (1749+91) * 100\n",
    "f1_lr = 2 * precision_lr * recall_lr / (precision_lr+recall_lr)\n",
    "print('acceracy: ', f'{acc_lr}', '%; ', 'precision: ', f'{precision_lr}', '%;\\n',\n",
    "      'recall: ', f'{recall_lr}', '%.', 'f1 score: ', f'{f1_lr}', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Precisionrecall.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy is the fraction of correct prediction.\n",
    "- Precision is the the fraction of relevant instances among the retrieved instances.\n",
    "- Recall is the fraction of relevant instances that have been retrieved over the total amount of relevant instances.\n",
    "- F1 score is the combination of precision and recall.\n",
    "<div align=\"right\">-- https://en.wikipedia.org/wiki/Precision_and_recall</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2: decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2158,    80],\n",
       "       [  105, 15579]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "model_dt = dt.fit(X_train, y_train)\n",
    "pred_dt = model_dt.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 0.9889601338165598%; precision: 0.9642537980339589%;\n",
      "recall: 0.9536014140521432%.f1 score: 0.9588980226616307\n"
     ]
    }
   ],
   "source": [
    "acc_dt = (2158+15579) / (2166+80+105+15584)\n",
    "precision_dt = 2158 / (2158+80)\n",
    "recall_dt = 2158 / (2158+105)\n",
    "f1_dt = 2 * precision_dt * recall_dt / (precision_dt+recall_dt)\n",
    "print('acceracy: ', f'{acc_dt}', '%; ', 'precision: ', f'{precision_dt}', '%;\\n',\n",
    "      'recall: ', f'{recall_dt}', '%.', 'f1 score: ', f'{f1_dt}', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 3: random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenjiazhai/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/wenjiazhai/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1570,   668],\n",
       "       [  101, 15583]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "model_rf = rf.fit(X_train, y_train)\n",
    "pred_rf = model_rf.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The false negative is much more than decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 4: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenjiazhai/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/wenjiazhai/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,  2238],\n",
       "       [    0, 15684]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "model_svm = svm.fit(X_train, y_train)\n",
    "pred_svm = model_svm.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This model (SVM) performs badly. I won't calculate model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Decision Tree outperforms other model. Try to optimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2142,    96],\n",
       "       [  113, 15571]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2 = DecisionTreeClassifier(criterion='entropy')\n",
    "model_dt2 = dt2.fit(X_train, y_train)\n",
    "pred_dt2 = model_dt2.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_dt2)\n",
    "# a slightly worse than original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 0.9877410007801182%; precision: 0.9486271036315324%;\n",
      "recall: 0.9498891352549889%.f1 score: 0.9492576999778418\n"
     ]
    }
   ],
   "source": [
    "acc_dt2 = (2142+15584) / (2166+96+113+15571)\n",
    "precision_dt2 = 2142 / (2162+96)\n",
    "recall_dt2 = 2142 / (2142+113)\n",
    "f1_dt2 = 2 * precision_dt2 * recall_dt2 / (precision_dt2+recall_dt2)\n",
    "print('acceracy: ', f'{acc_dt2}', '%; ', 'precision: ', f'{precision_dt2}', '%;\\n',\n",
    "      'recall: ', f'{recall_dt2}', '%.', 'f1 score: ', f'{f1_dt2}', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune max_dapth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2167,    71],\n",
       "       [  105, 15579]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt3 = DecisionTreeClassifier(criterion='gini', max_depth=10)\n",
    "model_dt3 = dt3.fit(X_train, y_train)\n",
    "pred_dt3 = model_dt3.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_dt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 0.9901796674478295%; precision: 0.9704433497536946%;\n",
      "recall: 0.9537852112676056%.f1 score: 0.9620421753607102\n"
     ]
    }
   ],
   "source": [
    "acc_dt3 = (2167+15579) / (2167+71+105+15579)\n",
    "precision_dt3 = 2167 / (2167+66)\n",
    "recall_dt3 = 2167 / (2167+105)\n",
    "f1_dt3 = 2 * precision_dt3 * recall_dt3 / (precision_dt3+recall_dt3)\n",
    "print('acceracy: ', f'{acc_dt3}', '%; ', 'precision: ', f'{precision_dt3}', '%;\\n',\n",
    "      'recall: ', f'{recall_dt3}', '%.', 'f1 score: ', f'{f1_dt3}', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The third model performs best. Tune min_samples_leaf based on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2167,    71],\n",
       "       [  108, 15576]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt4 = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_leaf=2)\n",
    "model_dt4 = dt4.fit(X_train, y_train)\n",
    "pred_dt4 = model_dt4.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_dt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 0.9900122754156903%; precision: 0.9682752457551386%;\n",
      "recall: 0.9525274725274725%.f1 score: 0.9603368047861732\n"
     ]
    }
   ],
   "source": [
    "acc_dt3 = (2167+15576) / (2167+71+108+15576)\n",
    "precision_dt3 = 2167 / (2167+71)\n",
    "recall_dt3 = 2167 / (2167+108)\n",
    "f1_dt3 = 2 * precision_dt3 * recall_dt3 / (precision_dt3+recall_dt3)\n",
    "print('acceracy: ', f'{acc_dt3}', '%; ', 'precision: ', f'{precision_dt3}', '%;\\n',\n",
    "      'recall: ', f'{recall_dt3}', '%.', 'f1 score: ', f'{f1_dt3}', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The third model still performs best. Next tune min_samples_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2168,    70],\n",
       "       [  105, 15579]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt5 = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_split=3)\n",
    "model_dt5 = dt5.fit(X_train, y_train)\n",
    "pred_dt5 = model_dt5.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_dt5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceracy: 0.9903470594799687%; precision: 0.968722073279714%;\n",
      "recall: 0.9538055433347998%.f1 score: 0.9612059410330304\n"
     ]
    }
   ],
   "source": [
    "acc_dt5 = (2168+15581) / (2168+70+105+15579)\n",
    "precision_dt5 = 2168 / (2168+70)\n",
    "recall_dt5 = 2168 / (2168+105)\n",
    "f1_dt5 = 2 * precision_dt5 * recall_dt5 / (precision_dt5+recall_dt5)\n",
    "print('acceracy: ', f'{acc_dt5}', '%; ', 'precision: ', f'{precision_dt5}', '%;\\n',\n",
    "      'recall: ', f'{recall_dt5}', '%.', 'f1 score: ', f'{f1_dt5}', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still the third model preforms best. Last to tune min_weight_fraction_leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2042,   196],\n",
       "       [  228, 15456]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt6 = DecisionTreeClassifier(criterion='gini', max_depth=10, min_weight_fraction_leaf=0.01)\n",
    "model_dt6 = dt6.fit(X_train, y_train)\n",
    "pred_dt6 = model_dt6.predict(X_validation)\n",
    "confusion_matrix(y_validation, pred_dt6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The accuracy significantly decrease. This model won't be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The conclusion is model 3 outperforms other models. Will use it to detect plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## split the dataset without TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only X_test_contest is useful, I don't care others.\n",
    "X_train_validation_contest, X_test_contest, y_train_validation, y_test = train_test_split(new_X, y, test_size=0.2, random_state=1988)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt_best = dt3.fit(X_train_validation, y_train_validation) # use a larger dataset\n",
    "predict = model_dt_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.Series(predict, index=X_test_contest.index)\n",
    "articles = pd.DataFrame({'articles':X_test_contest, 'citation':y_test, 'predict':predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plagiarism = articles.loc[(articles['citation']==0) & (articles['predict']==1)]\n",
    "# https://stackoverflow.com/questions/13611065/efficient-way-to-apply-multiple-filters-to-pandas-dataframe-or-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plagiarism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The conclusion is that there is no plagiarism!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
