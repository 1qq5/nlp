{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jieba cut words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first edition, runtime infinite..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token = []\n",
    "\n",
    "# with open(\"wiki_00\", \"r\") as file:\n",
    "#     tmp = []\n",
    "#     para = []\n",
    "#     for i, para in enumerate(file.read().split(\"\\n\")):\n",
    "#         tmp += re.findall(\"(\\w+)\", para)\n",
    "#         if i % 10000 == 0:\n",
    "#             print(i)\n",
    "#     for j in range(len(tmp)):\n",
    "#         tmp[j] = re.findall(\"[^0-9a-zA-Z]+\", tmp[j])\n",
    "#         # https://www.jianshu.com/p/acf73e6f53a9\n",
    "#         for s in tmp[j]:\n",
    "#             para += s\n",
    "#     token = list(jieba.cut(para))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## second edition\n",
    "not enough memory, have to use a smaller corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/pf/0lr435sj1qng8zc3xdkvcyfh0000gn/T/jieba.cache\n",
      "Loading model cost 0.871 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "token = []\n",
    "ptn = '[a-zA-Z0-9’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~]+'\n",
    "\n",
    "with open(\"output/AA/wiki_00\", \"r\") as file:\n",
    "    tmp = []\n",
    "    para = []\n",
    "    tmp += re.sub(ptn, \"\", file.read()) # keep Chinese characters only\n",
    "    para = ''.join(tmp).strip() # combine strings into a very long string\n",
    "    token = list(jieba.cut(para))\n",
    "    token = [s for s in token if s != \"\\n\"] # remove \"\\n\"\n",
    "# https://teamtreehouse.com/community/remove-all-instances-of-a-value-from-a-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['数学',\n",
       " '数学',\n",
       " '数学',\n",
       " '是',\n",
       " '利用',\n",
       " '符号语言',\n",
       " '研究',\n",
       " '數量',\n",
       " '结构',\n",
       " '变化',\n",
       " '以及',\n",
       " '空间',\n",
       " '等',\n",
       " '概念',\n",
       " '的',\n",
       " '一門',\n",
       " '学科',\n",
       " '从',\n",
       " '某种',\n",
       " '角度看',\n",
       " '屬',\n",
       " '於',\n",
       " '形式',\n",
       " '科學',\n",
       " '的',\n",
       " '一種',\n",
       " '數學',\n",
       " '透過',\n",
       " '抽象化',\n",
       " '和',\n",
       " '邏輯',\n",
       " '推理',\n",
       " '的',\n",
       " '使用',\n",
       " '由計數',\n",
       " '計算',\n",
       " '量度',\n",
       " '和',\n",
       " '對',\n",
       " '物體',\n",
       " '形狀及',\n",
       " '運動',\n",
       " '的',\n",
       " '觀察而產生',\n",
       " '數學家們',\n",
       " '拓展',\n",
       " '這些',\n",
       " '概念',\n",
       " '為',\n",
       " '了',\n",
       " '公式化',\n",
       " '新',\n",
       " '的',\n",
       " '猜想',\n",
       " '以及',\n",
       " '從',\n",
       " '選定',\n",
       " '的',\n",
       " '公理',\n",
       " '及定',\n",
       " '義中',\n",
       " '建立',\n",
       " '起',\n",
       " '嚴謹',\n",
       " '推導出',\n",
       " '的',\n",
       " '定理',\n",
       " '基礎',\n",
       " '數學',\n",
       " '的',\n",
       " '知識',\n",
       " '與',\n",
       " '運用',\n",
       " '總',\n",
       " '是',\n",
       " '個',\n",
       " '人',\n",
       " '與',\n",
       " '團體',\n",
       " '生活',\n",
       " '中',\n",
       " '不可或缺',\n",
       " '的',\n",
       " '一環',\n",
       " '對',\n",
       " '數學',\n",
       " '基本概念',\n",
       " '的',\n",
       " '完善',\n",
       " '早',\n",
       " '在',\n",
       " '古埃及',\n",
       " '美索',\n",
       " '不達米',\n",
       " '亞及',\n",
       " '古印度',\n",
       " '內',\n",
       " '的',\n",
       " '古代',\n",
       " '數學']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = [s for s in token if s != \"\\n\"]\n",
    "token[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count = Counter(token)\n",
    "# sorted(count, key=count.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n",
      "165\n"
     ]
    }
   ],
   "source": [
    "print(count['美麗'])\n",
    "print(count['漂亮'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1062d9320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'漂亮'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-56d82817c4ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mu'漂亮'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '漂亮'"
     ]
    }
   ],
   "source": [
    "model.wv.vocab[u'漂亮']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.wv.similarity('漂亮', '美麗')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(['美麗'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('壯觀' in token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['壯觀', '宏偉'], negative=['渺小'],topn=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
    "model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.vocab['cat']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
