{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finish the search problem\n",
    "\n",
    "Please using the search policy to implement an agent. This agent receives two input, one is @param start station and the other is @param destination. Your agent should give the optimal route based on Beijing Subway system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.\tGet data from web page.\n",
    "\n",
    "> a.\tGet web page source from: https://baike.baidu.com/item/%E5%8C%97%E4%BA%AC%E5%9C%B0%E9%93%81/408485\n",
    "\n",
    "> b.\tYou may need @package **requests**[https://2.python-requests.org/en/master/] page to get the response via url\n",
    "\n",
    "> c.\tYou may need save the page source to file system.\n",
    "\n",
    "> d.\tThe target of this step is to get station information of all the subway lines;\n",
    "\n",
    "> e.\tYou may need install @package beautiful soup[https://www.crummy.com/software/BeautifulSoup/bs4/doc/]  to get the url information, or just use > Regular Expression to get the url.  Our recommendation is that using the Regular Expression and BeautiflSoup both. \n",
    "\n",
    "> f.\tYou may need BFS to get all the related page url from one url. \n",
    "Question: Why do we use BFS to traverse web page (or someone said, build a web spider)?  Can DFS do this job? which is better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I parse Boston subway info instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re; import requests; from bs4 import BeautifulSoup\n",
    "url = \"https://www.mbta.com/schedules/\"\n",
    "red = requests.get(url+\"Red/line\")\n",
    "# soup = BeautifulSoup(red.text, 'html.parser')\n",
    "# print(soup.prettify())\n",
    "# print(red.text)\n",
    "ptn = re.compile(r'\"tooltip_text\":\\\"(\\S+)\\\".+\"longitude\":(-\\d+\\.\\d+),\"latitude\":(\\d+\\.\\d+)')\n",
    "re.findall(ptn, str(red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text\n",
    "{\"z_index\":null,\"tooltip_text\":\"Alewife\",\"tooltip\":null,\"size\":null,\"rotation_angle\":0,\"longitude\":-71.142483,\"latitude\":42.395428,\"id\":\"place-alfcl\",\"icon_opts\":null,\"icon\":\"stop-circle-bordered-expanded\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.\tPreprocessing data from page source.\n",
    "\n",
    "> a.\tBased on the page source gotten from url. You may need some more preprocessing of the page. \n",
    "\n",
    "> b.\tthe Regular Expression you may need to process the text information.\n",
    "\n",
    "> c.\tYou may need @package networkx, @package matplotlib to visualize data. \n",
    "\n",
    "> d.\tYou should build a dictionary or graph which could represent the connection information of Beijing subway routes. \n",
    "\n",
    "> e.\tYou may need the defaultdict, set data structures to implement this procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Build the search agent\n",
    "\n",
    "> Build the search agent based on the graph we build.\n",
    "\n",
    "for example, when you run: \n",
    "\n",
    "```python\n",
    ">>> search('奥体中心', '天安门') \n",
    "```\n",
    "you need get the result: \n",
    "\n",
    "奥体中心-> A -> B -> C -> ... -> 天安门"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As much as you can to use the already implemented search agent. You just need to define the **is_goal()**, **get_successor()**, **strategy()** three functions. \n",
    "\n",
    "> a.\tDefine different policies for transfer system. \n",
    "\n",
    "> b.\tSuch as Shortest Path Priority（路程最短优先）, Minimum Transfer Priority(最少换乘优先), Comprehensive Priority(综合优先)\n",
    "\n",
    "> c.\tImplement Continuous transfer. Based on the Agent you implemented, please add this feature: Besides the @param start and @param destination two stations, add some more stations, we called @param by_way, it means, our path should from the start and end, but also include the  @param by_way stations. \n",
    "\n",
    "e.g \n",
    "```\n",
    "1. Input:  start=A,  destination=B, by_way=[C] \n",
    "    Output: [A, … .., C, …. B]\n",
    "2. Input: start=A, destination=B, by_way=[C, D, E]\n",
    "    Output: [A … C … E … D … B]  \n",
    "    # based on your policy, the E station could be reached firstly. \n",
    "![image.png](attachment:image.png)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
