首先说明，上一节课的笔记跳过，因为 pylty 始终安装不了，还把我的 Mac 搞崩溃了...Mac 也会崩溃你敢信？

本节课（第六课）讨论了机器学习的一些基本知识。
# percentile/outlier
## percentile
假如我们将数据从小到大排列，25% percentile 指的是从小到大第 25% 位置的数，50% percentile 指的是中值（median），以此类推。
## outlier
中文称为“离群值”，指的是严重偏离其它数据点的数据点。通常来说，在一个符合正态分布的数据集里，离群值是大于 $\mu+3\sigma$或小于$\mu-3\sigma$的值。
# 训练集/验证集/测试集
很多时候需要试验多个模型，则将数据集分为训练集、验证集，使用训练集训练模型，然后使用验证集选择一个性能最佳的模型，最后将最佳模型应用于测试集。
# 机器学习的模型
## 决策树（Decision Tree）
决策树是一种根据不同条件分叉最终获得输出值的模型，分为分类树（Classification Tree）和回归树两种（Regression Tree），一般使用分类树。决策树一般采用递归区分（recursive partitioning）的方法，就是把数据分成更小的子集，直到到达终止条件。常见的算法有 ID3，C4.5，C5.0，1R，RIPPER 等。
- 优点：决策树易于理解和实现；对缺失值不敏感。
- 缺点：容易过拟合。

为了解决过拟合问题，科学家又提出了使用多棵树平均的方法，主要方法有：
- 装袋法（bagging 或 bootstrap aggregating）：均匀、有放回地选出 $m$ 个大小为 $n'$ 的子集 $ D_{i}$，作为新的训练集。在这 $ m $个训练集上使用分类、回归等算法，则可得到 $ m $个模型，再通过取平均值、取多数票等方法，即可得到 Bagging 的结果。Bagging 方法中最重要的算法为随机森林（random forest）。
- 提升树（boosting tree）：首先，第 1 个学习器对训练样本进行学习，当学习完成后，增大错误样本的权重，同时减小正确样本的权重，再利用第 2 个学习器对其进行学习，依次进行下去，最终得到 b 个学习器，最终，合并这 b 个学习器的结果。在 Boosting 方法中，最重要的算法为 AdaBoost 和 GBDT（梯度提升树，gradient boosting）。
## 朴素贝叶斯（Naive Bayers）
朴素贝叶斯是一种采用贝叶斯定理为理论基础的算法。具体算法细节这里就不讨论了。
- 优点：对噪音和缺失值不敏感
- 缺点：不适用于数值变量
## 线性回归（linear regression）
为一个数据集拟合一条直线  $y = k_0 + k_1*x_1 + ... k_n*x_n$ ($x_1$ 至 $x_n$ 为数据集中的特征），$y$ 为预测值。对线性回归进行改进后得到了 Lasso 和 Ridge 回归。
## 神经网络（neural network）
神经网络是一种非线性统计性数据建模工具，神经网络通常是通过一个基于数学统计学类型的学习方法（Learning Method）得以优化，所以也是数学统计学方法的一种实际应用，通过统计学的标准数学方法我们能够得到大量的可以用函数来表达的局部结构空间，另一方面在人工智能学的人工感知领域，我们通过数学统计学的应用可以来做人工感知方面的决定问题（也就是说通过统计学的方法，人工神经网络能够类似人一样具有简单的决定能力和简单的判断能力），这种方法比起正式的逻辑学推理演算更具有优势。（摘自维基百科）
# 模型性能的表征
首先定义一组数据：
![](pics/confusion_matrix)

## Accuracy：
预测结果与实际结果相同的百分比，如上例：$\frac{10+3}{10+1+2+3} = 81.25\%$
## Precision：
预测正确的真值与预测真值的百分比，如上例：$\frac{10}{10+1} = 90.9\%$
## Recall：
预测正确的真值与实际真值的百分比，如上例：$\frac{10}{10+2} = 83.3\%$
## F1 score：
有时候仅使用 Precision 和 Recall 并不能反映模型的真实性能，比如在 10000 封邮件中有 10 封垃圾邮件，假如全部标记为正常邮件，那么准确率达到了 99.99%，但是 10 封垃圾邮件全部没有过滤掉。因此引入 F1 score，公式为：$$F1 score = \frac{2*TP}{2*TP+FP+FN}$$
## AUC (Area Under Curve)
ROC曲线下方的面积，其意义是：

- 因为是在1x1的方格里求面积，AUC必在0~1之间。
- 假设阈值以上是阳性，以下是阴性；
- 若随机抽取一个阳性样本和一个阴性样本，分类器正确判断阳性样本的值高于阴性样本之几率 {\displaystyle =AUC} {\displaystyle =AUC}[1]。
- 简单说：AUC值越大的分类器，正确率越高。

从AUC判断分类器（预测模型）优劣的标准：

- AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。
- 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。
- AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。
- AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。
## 损失函数（loss function）
用来衡量模型性能的一个指标，数值越小说明性能越好。下面的 MSE 是损失函数的一种。
## 均方差（Mean squared error, MSE）：
损失函数的一种常用形式。
$$MSE = \frac{1}{n}\sum_{i=1}^{n}{(y_i - \hat{y_i})^2}$$
# 欠拟合/过拟合
## 过拟合
如果模型太复杂，可能会导致模型在训练集上效果很好而在测试集上效果很差的情况，称为过拟合。
## 欠拟合
与过拟合相反，如果模型在训练集上的效果已经很差，称为欠拟合。
# lazy learning/eager learning
## lazy learning
- 在接收数据的时候不学习
- 接收测试集之后开始建模
- 建模时间短，应用时间长
- 代表算法：K 近邻
## eager learning
- 在接收数据的时候即开始学习
- 建模时间长，应用时间短
-代表算法：决策树，朴素贝叶斯，神经网络
